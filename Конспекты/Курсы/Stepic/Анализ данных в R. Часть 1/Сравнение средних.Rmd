---
title: "Сравнение средних"
author: "Притчин Иван"
date: '13 мая 2018 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(dplyr)
library(magrittr)
library(ggplot2)
```

#### t-распределение Стьюдента

Подход, со сравнением средних, описанные в введении работает хорошо, пока число наблюдений является большим. Однако часто бывает, что число наблюдений бывает меньше 30. Оно нарушает предположение о том, что выборочные средние будут вести себя в соответствии с нормальным законом распределения.
```{r}
data <- rnorm(30)
x <- function(data, res_size) {
  res <- c()
  for (i in 1:res_size) {
    res <- c(res, mean(sample(data, size = 2/3*length(data))))
  }
  hist(res)
}
hist(data)
x(data, res_size = 40)
```

Если число наблюдений невелико, и $\sigma$ неизвестно, используется [t-распределение Стьюдента](student_distribution.jpg).
```{r}

```
Оно является унимодальным, симметричным, вероятность получить отклоняющиеся значения - выше.
Важным параметром t-распределения является степень свободы, которая зависит от числа наблюдений. Чем выше степень свободы - тем больше распределение стремится к нормальному. Число степеней свободы находит как
$$df = N - 1$$
В общем случае, число степеней свободны - количество элементов, которые могут вариироваться при расчете некоторого статистического показателя. К примеру, если у нас есть вектор из 10 элементов. Мы знаем его среднее. Нам нужно знать ещё 9 значений, чтобы восстановить 10 значение. Следовательно, тут 9 степеней свободы.
 
Пусть  $\overline{X}=10.8$, $sd=2$, $N = 25$, $\mu=10$.
Тогда $$se=\frac{sd_x}{\sqrt{n}}=0.4$$

Найдём вероятность получить такие или ещё более выраженные отличия.
$$z=\frac{\overline{X}-\mu}{se}=2$$
```{r}
pnorm(q = 2, mean = 0, sd = 1, lower.tail = FALSE)*2
pt(q = 2, df = 24, lower.tail = FALSE)*2
```


#### Сравнение двух средних, t-критерий Стьюдента
Пусть у нас есть две выборки. Известны $\overline{X}_1$, $sd_1$,$n_1$, $\overline{X}_2$, $sd_2$,$n_2$. нулевая гипотеза будет подразумевать, что нет никаких различий между этими двуми выборками.
$$H_0: M_1 = M_2$$
$$H_0: M_1 \neq M_2$$
Если верна нулевая гипотеза, то при многократном повторении эксперимента: многократно извлекали из генеральной совокупности по паре выборок находили их выборочные средние и разность между ними, то полученные значения подчинялись закону t-распределения со стандартной ошибокой (отклонением):

$$se=\sqrt{\frac{sd_1^2}{n_1}+\frac{sd_2^2}{n_2}}$$
и числом степеней свобод $df = n_1 + n_2 - 2$. Тогда t значение будет находиться как
$$t=\frac{(\overline{X}_1-\overline{X}_2)}{\sqrt{\frac{sd_1^2}{n_1}+\frac{sd_2^2}{n_2}}}$$
Полученное t-значение и при известном количестве степеней свобод мы можем основываясь на данных параметрах расчитать соответствующий p-уровень значимости, который нам скажет, какова вероятность получить такое или ещё более выраженное различие между двумя средними, если верна нулевая гипотеза.

Задача
Процесс денатурации ДНК представляет собой разрушение водородных связей между двумя цепями этой молекулы и очень сильно зависит от температуры, с которой мы воздействуем на молекулу. При сравнении двух видов были получены следующие показатели  
$M_1=89.9$, $sd_1=11.3$,$n_1=20$, $M_2=80.9$, $sd_2=11.7$,$n_2=20$
Выясним, являются ли полученные различия статистически значимыми.
Сформулируем наши гипотезы
$$H_0: M_1 = M_2$$
$$H_0: M_1 \neq M_2$$
При поставноке значений в формулу, получим примерно 2.5, т.е. разность между средними отклонилась от предполагаемого значения генеральной совокупности на 2.5$\sigma$ вправо. Число степеней свобод $df=n_1+n_2-2=20+20-2=38$. Рассчитаем интересующую нас вероятность.
```{r}
pt(q = 2.5, lower.tail = FALSE, df=38)*2
```
Отвергаем нулевую гипотезу.

При применении t-критерия Стьюдента надо держать в голове две вещи:  
1. Желательно равенство дисперсии внутри групп (гомогенность дисперсий)
2. Если объем выборки недостаточно большой (меньше 30 значений), то очень важным требованием является нормальность распределения наших двух выборок. Если число наблюдений больше 30, тогда t-тест хорошо справляется с задачей сравнения средних, даже если распределения отличаются от нормального.

### Проверка распределения на нормальность
Часто возникает необходимость проверить, является ли заданная величина нормально распределенной. Один из самых простых способов - построить гистограмму частот.

Ещё один способ - qqnorm 
```{r}
require(graphics)
n_dist <- rnorm(200)
qqnorm(n_dist)
hist(n_dist, breaks = 20)
t_dist <- rt(200, df = 5)
qqnorm(t_dist)
hist(t_dist, breaks = 20)
```

Часто для проверки гипотезы нормальности распределения используются тесты (Шапиро-Уилка тест)
Критерий Манна-Уитни переводит значения в ранговую шкалу, что позволяет более мягко работать с выбросами

### Однофакторный дисперсионный анализ
Пусть у нас есть три набора данных.
```{r}
data <- data.frame(
  set1 = c(3, 1, 2),
  set2 = c(5, 3, 4),
  set3 = c(7, 6, 5)
)
```
Нулевая гипотеза - все средние равны $M_1 = M_2 = M_3$.
Альтернативная гипотеза - найдутся пары из набора данных, которые не обладают равными средними.
Высчитаем среднее всех наблюдений
$$\overline{\overline{X}} = \frac{(3+1+2) + (5+3+4) + (7+6+5)}{9}=4$$
Высчитаем SST (считается как дисперсия, но без деления на n)
$$SST=(3-4)^2 + (1-4)^2 + (2-4)^2 + (5-4)^2 + (3-4)^2 + (4-4)^2 + (7-4)^2 + (6-4)^2 + (5-4)^2 = 30$$
Число степеней свободы $df = n - 1$. Общая сумма квадратом проистекат от двух источников: SSB (sum of square between groups), SSW (sum of squares within groups).

$$SSW=\sum_{group=1}^n\sum_{ob=1}^m(x_{group,i}- \overline{x_{group}})^2$$
$$SSW=[(3-2)^2 + (1-2)^2 + (2-2)^2] + [(5-4)^2 + (3-4)^2 + (4-4)^2] + [(7-6)^2 + (6-6)^2 + (5-6)^2]$$
Число степеней свободы $df = N-m = 6$

$$SSB=\sum_{group=1}^nlen(group)*(\overline{x_{group}}- \overline{\overline{x_{group}}})^2$$
$$SSB=3*(2-4)^2 + 3*(4-4)^2 + 3*(6-4)^2=24$$
$df=m-1=2$

Мы знаем, что $SST = 30$, из которых $SBB = 24$, $SSW = 6$. Если большая часть приходится на SBB - группы значительно различаются между собой, иначе мы говорили о том, что группы между собой не отличаются, и единственная изменчивость, которая у нас есть - внутри групповая.

Основным показателем дисперсионного анализа является F-назначение, которое находится как $$F=\frac{\frac{SSB}{m-1}}{\frac{SSW}{N-m}}=\frac{MS_{bg}}{MS_{wg}}$$
В нашем случае, $F$-критерий равен 12.
```{r}
pf(q = 12, df1 = 2, df2 = 6, lower.tail = FALSE)
pf(q = 3.5, df1 = 3, df2 = 16, lower.tail = FALSE)
```

#### Однофакторный дисперсионный анализ
Пусть даны следующий исходные данные
```{r}
data <- read.csv("datasets/genetherapy.csv")
```

Выдвенем нулевую гипотезу $H_0: M_1 = M_2 = M_3 = M_4$. В качестве зависимой переменной возьмём $M_x$, а за независимую переменную - тип терапии
```{r}
aov(expr ~ Therapy, data = data) %>% summary()
p <- ggplot(data, aes(Therapy, expr))
p + geom_boxplot(fill = "white", colour = "#3366FF")+ geom_jitter(width = 0.2)
```
Выводы: удалось выявить статистически значимую связь между типом терапии и показателем экспрессии гена. Всегда указывайте F-значение и p-уровень значимости.
Однако, нельзя просто взять и сравнить все группы между собой.

#### Множественное сравнение в ANOVA
Может показаться логичным вопрос, почему мы не можем языть и попарно сравнивать все группы между собой через t-критерий Стьюдента. Будем брать произвольное число выборок и попарно сравнивать между собой. Однако, с повышением числа выборок во взаимном сравнении, число экспериментов, в котором мы наблюдали статистически значимый результат возрастёт. Во избежание таких результатов можно выполнять различные поправки.

##### Поправка Бонферрони
Поправка Бонферрони заключается в снижении порога p-уровня значимости до значения $p/k$, где k - количество попарных сравнений. Поправка критикуется за сложность получения статистически значимых результатов. За сверхконсервативность. Применять Бонферрони не хорошо, существуют и другие решения.

##### [Поправка Тьюки](https://r-analytics.blogspot.ru/2013/10/blog-post_19.html#.Vucd_PA1GK0)
Первый шаг заключается в упорядочивании всех имеющихся групповых средних по возрастанию, с $1$ до $m$, где $m$ - число групп.
Второй шаг - выполнить попарные сравнения.Вначале сравнивается группа с наименьшим средним со всеми (начиная от большего к меньшему). Потом переход осуществляется к следующей группе. Несколько изменяется формула критерия:
$$q = \frac{\overline{x_B}-\overline{x_A}}{SE}$$
где $SE$
$$SE = \sqrt{\frac{MS_w}{n}}$$
где $MS_w$ - внутри групповая дисперсия. Данная формула работает, если количество элементов в сравнимаемых группах равны между собой. Если количество элементов различное, применяется другая формула:
$$SE = \sqrt{\frac{MS_w}{2}(\frac{1}{n_A}+ \frac{1}{n_B})}$$
```{r}
waterbodies <- data.frame(Water = rep(c("Grayson", "Beaver",
                                       "Angler", "Appletree",
                                       "Rock"), each = 6),
                          Sr = c(28.2, 33.2, 36.4, 34.6, 29.1, 31.0,
                                 39.6, 40.8, 37.9, 37.1, 43.6, 42.4,
                                 46.3, 42.1, 43.5, 48.8, 43.7, 40.1,
                                 41.0, 44.1, 46.4, 40.2, 38.6, 36.3,
                                 56.3, 54.1, 59.4, 62.7, 60.0, 57.3)
                          )

```
Необходимо выяснить:
1) есть ли существенные различия между этими водоёмами по содержанию стронция в целом и, если есть, 
2) какие именно водоемы отличаются друг от друга. 
Для ответа на первый вопрос выполним дисперсионный анализ при помощи функции aov()

```{r}
M <- aov(Sr ~ Water, data = waterbodies)
summary(M)
```

Для решения 2 задачи воспользуемся функцией TukeyHSD(M)
```{r}
res <- TukeyHSD(M)
```

Если значение 0 включено в диапазон между [lwr, upr], и p agj < 0.05 значит между парой переменных обнаружена статистически значивая связь, а конкретно в нашем случае
```{r}
res <- broom::tidy(res)
#пары, между которыми найдены статистически значимые отличия
res[res$adj.p.value < 0.05 & !(res$conf.low < 0 & res$conf.high > 0), c("comparison")]
```

Существуют и другие поправки на множественное сравнение.

#### Двуфакторный дисперсионный анализ
Сравнение средних, где зависимыми переменными являются две факторные переменные. Исследовался уровень экспрессии гена в зависимости от возраста и дозировки лекарства.
```{r}
data <- read.csv("datasets/atherosclerosis.csv")
head(data)
str(data)

fit = aov(formula = expr ~ dose + age, data)
summary(fit)
```
По результатам можем сказать, что возраст вносит существенный вклад в значение среднего, в отличие от дозировки.
Значимый эффект для фактора возраста $F(1,61) = 7,57$, $p < 0.05$
Незначивый эффект для фактора подготовки $F(1,61) = 0.64$, $p > 0.05$

Основная идея, которая лежит в основе двуфакторного дисперсионного анализа сводится к тому, что 
$$SST = SSW + SSB_A + SSB_B + SSB_{A*B}$$
Рассмотрим ещё один пример
```{r}
data <- read.csv("datasets/birds.csv")
head(data)
str(data)

fit = aov(formula = var4 ~ hormone + sex + hormone *sex, data)
summary(fit)
```
Как мы видим, сами факторы по отдельное не дают значимого вклада. Для нас статистически значимым результатом является взаимодействие факторов. Под взаимодействием факторов понимается влияние одного фактора по разному проявляется на зависимую переменную в зависимости от градации другого фактора.
Можно производить исследования для произвольного числа факторов.

Требования к данным
- нормально распределения
- гомогенность дисперсий (тест Левина)

При числе наблюдений больше 50, дисперсионный анализ устойчив к нарушениям ограничений.
Результаты дисперсионного анализа не позволяют ничего говорить о причинно следственной зависимости.